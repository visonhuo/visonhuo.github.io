---
title: "缓存更新的常见模式"
date: 2022-03-03T16:48:49+08:00
lastmod: 2022-03-03T16:48:49+08:00
draft: true
author: visonhuo
description: "缓存是一种性能优化的常用手段，缓存本质是真实数据的内存副本，为了保证副本与真实数据保持一致，我们需要对缓存进行更新操作，本文将对缓存更新的常用模式进行介绍。"
featuredImage: "/images/feature/architecture_design/cache_update_patterns.png"
featuredImagePreview: "/images/feature/architecture_design/cache_update_patterns.png"
categories: ["架构设计"]
tags: ["缓存设计"]
---
<!--more-->

## 前言
在计算机领域，**缓存** 是一个相当重要的概念，属于常见的性能优化手段。
其本质工作在于 **提高 I/O 效率**，将部分经常访问的数据从 I/O 效率较低的设备中，拷贝到 I/O 效率更高的介质中，以此来提升整体的性能。

{{< admonition type=tip title="I/O 效率是相对的" open=open >}}
这里我们需要理解，**介质的 I/O 效率是相对的**。比如说磁盘对于内存来说，是性能更低的 I/O 设备，
但本地磁盘对于网络 I/O 来说又是性能更高的存在。

所以对于磁盘来说，内存可以作为其缓存介质；对于网络 I/O 来说，磁盘可以其缓存介质。
不要将缓存局限于磁盘和内存的场景，我们会有一个不一样的视野。
{{< /admonition >}}

所以缓存的数据本质是底层存储的副本，在提升读取效率的同时，带来了一致性相关的问题。
当底层数据更新时，我们需要同时更新缓存数据，否则就会出现数据不一致的情况。

而在本文中，将对常见的更新模式进行一个小总结，主要包括如下内容：
- [ ] 缓存更新的常见问题
- [ ] 4 种缓存更新模式
- [ ] 生产环境中的缓存更新方案

## 缓存更新的常见问题
在日常开发中，缓存最常见的使用场景就是用于缓解 DB 压力，将数据放置在内存中。
那这里就涉及到前面提到的问题：**如何保障数据更新后, 两端数据的一致性？**
以下我们来看一些常见的数据不一致情况。

### 先写缓存，再写数据库
#### 读写场景（Del缓存）
{{< image src="https://i.bmp.ovh/imgs/2022/03/2776afb1bacdf43b.png" width="750" caption="一个线程更新数据，一个线程读取数据" >}}
如图所示，以下是正常情况下我们期望的时序操作：

1. 线程 A 先删除 Cache ;

2. 线程 A 写入最新数据到 DB ;

3. 线程 B 读取 Cache , 发现 Cache Miss ;

4. 线程 B 从 DB 读取数据 ;

5. 线程 B 将读取到的数据写入到 Cache 中;

但因为是并发的场景，所以上述步骤的 **执行顺序是没有保障的**。

假设 Step2 更新 DB 的操作比较耗时，此时线程 B 已经将旧的数据读取出来（即 Step3，Step4 先于 Step2），
并且将更新前的值写入到缓存中，那么读取缓存将会一直得到旧数据，出现了数据不一致的情况。

#### 双写场景 (Update缓存)
{{< image src="https://i.bmp.ovh/imgs/2022/03/015c9d640863b8f1.png" width="600" caption="两个线程同时更新缓存" >}}
如图所示，以下是正常情况下我们期望的时序操作:

1. 线程 A 将值写入 Cache ;

2. 线程 A 将值写入 DB ;

3. 线程 B 将最新值写入 Cache ;

4. 线程 B 将最新值写入 DB ;

同样因为是并发的场景, 可能出现：
1. 线程 B 写入缓存的值被线程 A 覆盖；（线程 B 写入缓存操作先执行）

2. 线程 B 比线程 A 后写入 DB ;

此时 DB 的值为线程 B 写入的值, 但在缓存中的值确是线程 A 写入的值, 再次出现数据不一致的情况;

### 先写数据库, 再写缓存
#### 双写场景 (Update缓存)
跟上述的双写场景类似, 期望的场景:
1. 线程 A 将值写入 DB ;

2. 线程 A 将值写入 Cache ;

3. 线程 B 将值写入 DB ;

4. 线程 B 将值写入 Cache ;

同样存在跟上面一样的问题，因为在线程中无论是写 DB 和写 Cache 的操作都不是 **原子** 的（无法保证同时执行），所以无法保证顺序。
只要不能保证更新的顺序，就可能会出现 DB 和 Cache 数据不一致的情况。

#### 双写场景 (Del缓存)
同样跟上述操作步骤类似，只是 **Update Cache** 变成了 **Delete Cache** 的操作。

这个 Case 是没有问题的，因为无论如何操作，更新之后的 Cache 中值为空，所以不会出现数据不一致的情况。

{{< admonition type=question title="Update 和 Delete 的区别" open=open >}}
Update 操作的本质问题在于其是 **有状态操作**，我们需要将更新值写入 Cache ，而每次写入的值可能是不同的，所以它是有状态的。
在该架构中，我们写数据库和写缓存本质上是 **两个操作** ，不具备原子性，所以在不同线程中是无法保证其写入顺序的。
也就是说，**存在状态的、非原子双写操作，都会有数据不一致的风险**。

而 Delete 操作是 **幂等操作**, 不管是哪个线程删除缓存都会得到一致的结果，
即最终只存在 DB 中的值，Cache 中没有任何值，所以它是安全的。
{{< /admonition >}}

#### 一读一写 (Del缓存)
{{< image src="https://i.bmp.ovh/imgs/2022/03/412a0623cc0ecd35.png" width="750" caption="一个线程更新数据（Delete Cache），一个线程读取数据" >}}

如上图所示, 以上流程的执行步骤:
1. 线程 A 将值写入 DB ;

2. 线程 A 删除对应的 Cache ;

3. 线程 B 发起一个读取请求, 发现 Cache Miss ;

4. 线程 B 从 DB 获取最新数据;

5. 线程 B 将数据写入 Cache ;

这种方式是较为常见的场景，但仍然是不完美的，当出现：
- 在线程 A 成功写入之前，线程 B 就读取到 DB 中的旧值了；

- 在线程 B 写入缓存之前，线程 A 已经将缓存给删除了（意味着后续不会有删除缓存的操作了）；

当满足以上两个条件时, 就会出现数据不一致的情况, 只是这种情况在正常代码逻辑中很少见, 除非：
1. 在更新方法中, 写入 DB 之后马上删除 Cache ；

2. 在查询方法中, 查询 DB 之后, 执行了一段耗时操作, 才将一开始读取的值写入 Cache ； (Bad Practice)

虽然我们可以在代码逻辑中避免该类问题，但理论上，该方法仍然是有缺陷的。
在文章后面将会介绍另外一种缓存更新的方式来彻底避免上述时序问题。

### 常见问题小结
综上所述的所有场景, 有以下结论：

- 更新缓存应该使用 Delete 操作，而不是 Update 操作；

- 先更新数据库，再更新缓存的操作更加安全；（但不完美）

- 应该为所有的缓存设置 **过期时间**，因为所有 Case 都无法保证 100% 的一致性；

## 缓存更新模式
### Cache Aside Pattern
该模式是日常开发中最常用的模式, 包含几种情况:
- **缓存失效** ：应用程序先从 cache 中取数据，如果没有得到，则从数据库中获取，成功后将值放到缓存中；

- **缓存命中** ：应用程序从 cache 中取数据，取到之后直接返回；

- **数据更新** ：先把数据存放到数据库中，成功之后再让缓存失效;

{{< image src="https://i.bmp.ovh/imgs/2022/03/bb9825323e52ee3e.png" width="750" caption="缓存失效场景" >}}

{{< image src="https://i.bmp.ovh/imgs/2022/03/6baac2fcd0c44975.png" width="750" caption="缓存更新场景" >}}


这种模式也就对应前面说的 **先写数据库，再删缓存** 的情况。
虽然这个方案仍存在数据不一致的情况，但出现的概率是比较小了，配合过期时间机制，大多数情况下都能工作良好。
并且比起通过 2PC 或者是 Paxos 协议来保证一致性，这种努力降低并发时脏数据的概率的方式，会更适用于这种缓存的场景。

### Read Through
在 Cache Aside模式中，应用需要维护两个数据存储：Cache + DB 。
所以无论是更新还是读取操作，在应用代码中都需要执行两个步骤 (操作Cache, 操作DB) 来实现。

而在 Read/Write Through 模式中，则是把更新 DB 的操作由缓存层进行代理。
对于应用层来说，就只需要面对一个单一存储进行开发，由存储自己维护 Cache 进而简化应用层代码；

**Read Through Pattern**，就是指在查询操作中更新缓存。
当 Cache Miss 时，Cache Aside 是由调用方负责把数据加载到缓存中，
而 Read Through 则是由缓存服务自己来进行加载，对于应用层来说是透明的。

这里需要补充的一点就是：这里的缓存服务并非直接指 Redis 或 Memcached ，
也可以是应用中的一个缓存层。比如 Spring 中 Cache 相关的注解，
因为对于应用层代码来说，缓存的更新/删除并不需要调用方参与，完全由 Spring Cache 代理操作了，也是符合 Read Through Pattern 模式的。
```Java
import org.springframework.cache.annotation.Cacheable;
import org.springframework.stereotype.Component;

@Component
public class MathService {
    @Cacheable("piDecimals")
    public int computePiDecimal(int i) {
        // ...
    }
}
```

### Write Through
Write Through 与 Read Through 类似，不过发生在更新数据的时候。当有数据更新时，

- 如果没有命中缓存, 则直接更新数据库, 然后返回;

- 如果命中缓存, 则更新缓存, 然后再由 Cache 自己更新数据库; (同步操作)

流程如上图所示, 这里需要注意一个问题: 该模式存在状态双写问题, 所以就像上面提到的, 如果 Cache 自己更新数据库的话, 则需要保证针对单条 key 的更新操作是同步的, 否则同样会有数据不一致的风险; 这种方式在生产环境中, 比较少见.

### Write Behind Caching Pattern
Write Behind (也称为Write Back) 就是指 : 更新数据时, 先更新缓存, 不会立即更新数据库, 缓存会异步地批量更新到数据库中. 这种方式的好处在于减少单次 I/O 操作, 一次写入更多数据以此来提升 I/O 性能. 因为是先写缓存, Write Back 还可以合并对于同个数据的多次操作, 在并发很大的情况下, 性能的提高是相当可观的. 比如 Linux 文件系统中的 Page Cache 算法 (文件写入, 先写 Cache , 操作系统会等待合适的时机将 Page Cache 刷回到磁盘), 就是使用了类似的思想.

该模式的缺点: 因为数据没有立即落盘, 如果此时系统宕机, 则存在丢失数据的风险. (强一致性 VS 高性能?)
Write Back 的实现逻辑比较复杂, 因为它需要 track 有哪些数据是被更新了, 然后再将这些数据刷到持久层上. 操作系统的 Write Back 会在仅当这个 Cache 需要失效时 (内存不够, 进程退出等), 才会被真正保存起来, 通常也可以称为 Lazy Write. 如下图所示:

其实这种方式在日常开发中, 在高并发写的场景也会使用到. 通常高并发写场景我们会通过 MQ 去进行削峰操作, 这种方式可以保证数据不丢 (假设 MQ 是稳定的, 包含持久化存储的, 如 Kafka). 但是对于不是很重要的数据, 比如说 Banner 点击计数器, 我们可以在应用中实现一个内存计数器, 先在内存中累加点击数, 然后再通过定时器或者其他触发机制将数据回刷到 DB 中, 这样也能提升系统的性能;


## 生产环境中的缓存更新方案
除了 Cache Aside Pattern 之外, 实际项目中比较常见的另外一种方案就是:
● 通过某些中间件同步 MySQL 的 binlog; (实际项目中使用的是 Canal 同步 binlog)
● 通过 MQ 将数据修改的消息发送到应用程序;
● 应用程序启动一个 Message Handler 专门负责接收数据更新消息, 并且清理缓存;

这种方式的好处在于: 能保障系统最终一致 , 因为:
● 数据库只有事务成功后 (binlog写入成功), 才会发送更新操作, 触发缓存清理的逻辑; 也就意味着, 每个数据更新都有一个对应的缓存清理的操作, 所以能保证最后应用层还是要来查一遍最新数据的;
● MQ 一般是包含重试机制的, 理论上能够给保障最终旧的缓存一定会被清理掉;

如何处理一主多从的情况?
一般存在 MySQL 一主多从的情况, 应用层也应该会存在读写分离的策略. 也就是说, 应用层部分的查询请求会走到从库中. 如果有这种 Case 的话, 我们就不能指监听主库的更新了, 也需要监听从库的更新.

如果不监听从库的修改, 则如下步骤会出现问题:
1. 主库的数据被修改了;
2. 发送数据更新消息给到应用层, 应用层删除了缓存;
3. 从库还没有更新到最新数据时, 有个查询请求过来, 读取从库得到旧值;
4. 将这个旧值写入了缓存;
   如果后续主库上关于这个记录没有变更操作了, 则缓存值将一直是错误的;

关于监听多个从库的方案, 有一个小问题:
我们无法区分哪一个从库将会是最晚被同步到的库, 所以只能是每次来一个更新消息, 就执行一次 Del Cache 的操作. 假设是 1主5从 的情况, 那么每一个 DB 更新操作都需要对应执行 6 次 Del Cache 的操作, 虽然并不会影响很多, 但是这种方式还是有点不优雅~


如何处理本地缓存的情况?
实际项目中, 根据缓存存放的位置, 一般分为两种:
● 集中式缓存 : 单一服务, 用于提供缓存操作, 比如 Redis ;
● 本地缓存 : 集成在应用内部, 使用本机的内存, 比如 Guava Cache ;

因为集中式缓存是存放在单个服务中的, 而本地缓存是分散在不同机器的, 所以删除的策略也有所不同:
● 集中式缓存 : 所有的机器可以在一个 Kafka 的 Consumer Group 中, 只要有一个 Consumer 去执行对应的 Del Cache 的操作即可, 修改对所有机器都可见;
● 本地缓存 : 所有机器都有各自的 Consumer Group, 每个 Consumer Group 中只包含单台机器, 所以更新操作的消息会被所有的机器接受处理, 就能将所有机器的本地缓存统一删除掉;


如何处理数据立即读取的情况?
通过同步 binlog 删除缓存的方式是一种全局、统一的解决方案, 通常来说, 能解决开发中 95% 的情况. 但是这种方式相对于 Cache Aside 的模式, 存在如下问题:
● 更新延迟 : 所有删除缓存的信号, 要从 MySQL -> Canal -> Kafka -> 应用程序, 整个链路比 Cache Aside 长很多, 所以缓存何时会被删除, 是没有很强的保障的;
● 大规模故障 : 同样, 因为存在节点多, 所以链路上的任何一个环节如果出现了问题, 所有的缓存更新操作就会停滞. 相比于 Cache Aside 自己控制缓存的模式, 更容易发生大规模的故障;

如果系统中确实存在一旦更新, 就可能会立即读取值的情况, 比如实际一个业务场景 (用户配置 + 预览页面) :
● 用户在配置页面修改展示相关的配置, 服务端发送消息通知预览页配置变更了;
● 预览页此时要过来服务端拉取最新配置进行展示;
这种场景的问题就是: 更新后, 立马读取. 如果此处使用 Canal 更新缓存的方式, 那么缓存更新的时机是没有绝对保障的. 此时就可以转用 Cache Aside 的模式, 用户执行更新操作之后, 在代码中手动执行删除缓存的操作, 以此来满足这种对更新延迟比较敏感的场景;



## Reference
https://juejin.cn/post/6844903907726983181
https://coolshell.cn/articles/17416.html