---
title: "缓存更新模式"
date: 2022-03-03T16:48:49+08:00
lastmod: 2022-03-03T16:48:49+08:00
draft: true
author: visonhuo
description: "缓存是一种性能优化的常用手段，缓存本质是真实数据的内存副本，为了保证副本与真实数据保持一致，我们需要对缓存进行更新操作，本文将对缓存更新的常用模式进行介绍。"
featuredImage: "/images/feature/architecture_design/cache_update_patterns.png"
featuredImagePreview: "/images/feature/architecture_design/cache_update_patterns.png"
categories: ["架构设计"]
tags: ["缓存"]
---
<!--more-->

## 前言
在计算机领域，**缓存** 是一个相当重要的概念，属于常见的性能优化手段。
其本质工作在于 **提高 I/O 效率**，将部分经常访问的数据从 I/O 效率较低的设备中，拷贝到 I/O 效率更高的介质中，以此来提升整体的性能。

{{< admonition type=tip title="I/O 效率是相对的" open=open >}}
这里我们需要理解，**介质的 I/O 效率是相对的**。比如说磁盘对于内存来说，是性能更低的 I/O 设备，
但本地磁盘对于网络 I/O 来说又是性能更高的存在。

所以对于磁盘来说，内存可以作为其缓存介质；对于网络 I/O 来说，磁盘可以其缓存介质。
不要将缓存局限于磁盘和内存的场景，我们会有一个不一样的视野。
{{< /admonition >}}

所以缓存的数据本质是底层存储的副本，在提升读取效率的同时，带来了一致性相关的问题。
当底层数据更新时，我们需要同时更新缓存数据，否则就会出现数据不一致的情况。

而在本文中，将对常见的更新模式进行一个小总结，主要包括如下内容：
- [ ] 缓存更新的常见问题
- [ ] 4 种缓存更新模式
- [ ] 生产环境中的缓存更新方案

## 缓存更新的常见问题
在日常开发中，缓存最常见的使用场景就是用于缓解 DB 压力，将数据放置在内存中。
那这里就涉及到前面提到的问题：**如何保障数据更新后, 两端数据的一致性？**
以下我们来看一些常见的数据不一致情况。

### 先写缓存，再写数据库
#### 读写场景（Del缓存）
{{< image src="https://i.bmp.ovh/imgs/2022/03/2776afb1bacdf43b.png" width="750" caption="一个线程更新数据，一个线程读取数据" >}}
如图所示，以下是正常情况下我们期望的时序操作：

1. 线程 A 先删除 Cache ;

2. 线程 A 写入最新数据到 DB ;

3. 线程 B 读取 Cache , 发现 Cache Miss ;

4. 线程 B 从 DB 读取数据 ;

5. 线程 B 将读取到的数据写入到 Cache 中;

但因为是并发的场景，所以上述步骤的 **执行顺序是没有保障的**。

假设 Step2 更新 DB 的操作比较耗时，此时线程 B 已经将旧的数据读取出来（即 Step3，Step4 先于 Step2），
并且将更新前的值写入到缓存中，那么读取缓存将会一直得到旧数据，出现了数据不一致的情况。

#### 双写场景 (Update缓存)
{{< image src="https://i.bmp.ovh/imgs/2022/03/015c9d640863b8f1.png" width="600" caption="两个线程同时更新缓存" >}}
如图所示，以下是正常情况下我们期望的时序操作:

1. 线程 A 将值写入 Cache ;

2. 线程 A 将值写入 DB ;

3. 线程 B 将最新值写入 Cache ;

4. 线程 B 将最新值写入 DB ;

同样因为是并发的场景, 可能出现：
1. 线程 B 写入缓存的值被线程 A 覆盖；（线程 B 写入缓存操作先执行）

2. 线程 B 比线程 A 后写入 DB ;

此时 DB 的值为线程 B 写入的值, 但在缓存中的值确是线程 A 写入的值, 再次出现数据不一致的情况;

### 先写数据库, 再写缓存
#### 双写场景 (Update缓存)
跟上述的双写场景类似, 期望的场景:
1. 线程 A 将值写入 DB ;

2. 线程 A 将值写入 Cache ;

3. 线程 B 将值写入 DB ;

4. 线程 B 将值写入 Cache ;

同样存在跟上面一样的问题，因为在线程中无论是写 DB 和写 Cache 的操作都不是 **原子** 的（无法保证同时执行），所以无法保证顺序。
只要不能保证更新的顺序，就可能会出现 DB 和 Cache 数据不一致的情况。

#### 双写场景 (Del缓存)
同样跟上述操作步骤类似，只是 **Update Cache** 变成了 **Delete Cache** 的操作。

这个 Case 是没有问题的，因为无论如何操作，更新之后的 Cache 中值为空，所以不会出现数据不一致的情况。

{{< admonition type=question title="Update 和 Delete 的区别" open=open >}}
Update 操作的本质问题在于其是 **有状态操作**，我们需要将更新值写入 Cache ，而每次写入的值可能是不同的，所以它是有状态的。
在该架构中，我们写数据库和写缓存本质上是 **两个操作** ，不具备原子性，所以在不同线程中是无法保证其写入顺序的。
也就是说，**存在状态的、非原子双写操作，都会有数据不一致的风险**。

而 Delete 操作是 **幂等操作**, 不管是哪个线程删除缓存都会得到一致的结果，
即最终只存在 DB 中的值，Cache 中没有任何值，所以它是安全的。
{{< /admonition >}}

#### 一读一写 (Del缓存)
{{< image src="https://i.bmp.ovh/imgs/2022/03/412a0623cc0ecd35.png" width="750" caption="一个线程更新数据（Delete Cache），一个线程读取数据" >}}

如上图所示, 以上流程的执行步骤:
1. 线程 A 将值写入 DB ;

2. 线程 A 删除对应的 Cache ;

3. 线程 B 发起一个读取请求, 发现 Cache Miss ;

4. 线程 B 从 DB 获取最新数据;

5. 线程 B 将数据写入 Cache ;

这种方式是较为常见的场景，但仍然是不完美的，当出现：
- 在线程 A 成功写入之前，线程 B 就读取到 DB 中的旧值了；

- 在线程 B 写入缓存之前，线程 A 已经将缓存给删除了（意味着后续不会有删除缓存的操作了）；

当满足以上两个条件时, 就会出现数据不一致的情况, 只是这种情况在正常代码逻辑中很少见, 除非：
1. 在更新方法中, 写入 DB 之后马上删除 Cache ；

2. 在查询方法中, 查询 DB 之后, 执行了一段耗时操作, 才将一开始读取的值写入 Cache ； (Bad Practice)

虽然我们可以在代码逻辑中避免该类问题，但理论上，该方法仍然是有缺陷的。
在文章后面将会介绍另外一种缓存更新的方式来彻底避免上述时序问题。

### 常见问题小结
综上所述的所有场景, 有以下结论：

- 更新缓存应该使用 Delete 操作，而不是 Update 操作；

- 先更新数据库，再更新缓存的操作更加安全；（但不完美）

- 应该为所有的缓存设置 **过期时间**，因为所有 Case 都无法保证 100% 的一致性；

## 缓存更新模式
### Cache Aside Pattern
该模式是日常开发中最常用的模式, 包含几种情况:
- **缓存失效** ：应用程序先从 cache 中取数据，如果没有得到，则从数据库中获取，成功后将值放到缓存中；

- **缓存命中** ：应用程序从 cache 中取数据，取到之后直接返回；

- **数据更新** ：先把数据存放到数据库中，成功之后再让缓存失效;

{{< image src="https://i.bmp.ovh/imgs/2022/03/bb9825323e52ee3e.png" width="660" caption="缓存失效场景" >}}

{{< image src="https://i.bmp.ovh/imgs/2022/03/6baac2fcd0c44975.png" width="660" caption="缓存更新场景" >}}

这种模式就对应了前面说的 **先写数据库，再删缓存** 的场景。
尽管这个方案仍存在数据不一致的情况，但出现的概率是比较小了，配合过期时间机制，大多数情况下都能工作良好。

### Read Through
在 Cache Aside 模式中，应用需要维护两个数据存储：Cache + DB 。
所以无论是更新还是读取操作，在应用代码中都需要执行两个步骤 (操作Cache, 操作DB) 来实现。

而在 Read/Write Through 模式中，则是直接把更新 DB 的操作交由缓存层代理。
对于应用层来说，就只需要面对一个单一存储进行操作，由这个存储组件来维护 Cache 进而简化应用层代码；

**Read Through Pattern**，就是指在查询操作中更新缓存。
当 Cache Miss 时，Cache Aside 是由调用方负责把数据加载到缓存中，
而 Read Through 则是由缓存服务自己来进行加载，对于应用层来说是透明的。

需要注意，这里的缓存并非直接指 Redis 或 Memcached 这类缓存组件，也可以是应用中的一个缓存层。
比如 Spring 中 Cache 代理注解，对于应用层代码来说，缓存的更新/删除并不需要调用方参与，
完全由 Spring Cache 代理执行了，也是符合 Read Through Pattern 的。
```Java
import org.springframework.cache.annotation.Cacheable;
import org.springframework.stereotype.Component;

@Component
public class MathService {
    @Cacheable("piDecimals")
    public int computePiDecimal(int i) {
        // ...
    }
}
```

### Write Through
Write Through 与 Read Through 类似，不过其发生在更新数据时。当更新数据是：

- 如果没有命中缓存, 则直接更新数据库, 然后返回;

- 如果命中缓存, 则更新缓存, 然后再由 Cache 自己更新数据库; (同步操作)

{{< image src="https://i.bmp.ovh/imgs/2022/03/d0c2a6fd65d53de5.png" width="450" caption="Read/Write Through模式" >}}

如上图所示，当缓存中存在数据时，则直接更新缓存中的值，稍后再由系统将更新持久化到底层存储中。

这里存在一些细微的并发问题，当读取和更新并发时：

1. 线程 A 读取到当前值1 ；

2. 线程 B 写入值2，当前最新值为 2 ；

3. 线程 A 将值1写入缓存 ；

4. 线程 C 发现缓存命中，更新值1为值3 ；

5. 当系统将缓存中的值刷入磁盘时，结果覆盖了值2 ；

所以在这种模式下，需要对数据的操作进行一些同步处理，避免这种数据冲突的问题。
操作系统中的 Page Cache 就是标准的 Read/Write Through 模式，可以参考其是如何工作的。 

### Write Back Caching Pattern
Write Back（又叫Write Behind），其核心思想在于：**更新数据时，先更新缓存，不会立即更新数据库，缓存会异步地批量更新到数据库中。**

这种方式的好处在于减少 I/O 操作，一次写入更多数据以此来提升 I/O 性能。
因为是先写缓存，该模式还可以合并对于同个数据的多次操作，在并发很大的情况下，性能的提高是相当可观的。
比如 Linux 文件系统中的 Page Cache 算法，当我们进行文件写入时，其就是先写缓存，操作系统会等待合适的时机将 Page Cache 刷回到磁盘，就是使用了类似的思想。

该模式的缺点同样明显，因为数据没有立即落盘，如果此时系统宕机，则存在丢失数据的风险，需要我们在持久化和高性能之间做权衡。
Write Behind 的实现逻辑比较复杂，因为它需要记录有哪些数据是被更新了，然后再将这些数据刷到持久层上。
操作系统的 Write() 系统调用会在仅当这个 Cache 需要失效时（如内存不够, 进程退出等情况），才会被真正保存起来，通常也可以称为 Lazy Write 。 如下图所示:

{{< image src="https://i.bmp.ovh/imgs/2022/03/77336dac8ea8e1ea.png" width="450" caption="Write Back Caching 模式" >}}

其实这种方式在日常开发中，在高并发写的场景也会使用到。
通常高并发写场景我们会通过 MQ 去进行削峰操作，
这种方式可以保证数据不丢 (假设 MQ 是稳定的, 包含持久化存储的, 如 Kafka)。
但是对于不是很重要的数据，比如说 Banner 点击计数器，
我们可以在应用中实现一个内存计数器，先在内存中累加点击数，
然后再通过定时器或者其他触发机制将数据回刷到 DB 中，这样也能提升系统的性能;

## 生产环境中的缓存更新方案
### 基于 Binlog 事件
在传统的 Cache Aside 模式中，我们往往是在更新数据库操作成功之后，由应用程序层将缓存删除掉，这一切都发生在应用层。
这种方式有几个明显的坏处：
1. 缓存删除操作可能失败，尤其当使用 Redis 这一类分布式缓存组件时，因为需要进行网络请求；

2. 为了保障数据的一致性，当缓存删除失败时，我们需要终止整个事务，或者重试删除缓存操作直至成功；

3. 上面删除缓存的逻辑需要我们手动集成到代码中每一个数据库更新操作中，存在人为隐患；

幸好我们现在有了一些用于同步 DB Binlog 的组件，比如 Alibaba Canal 等，
这类组件可以伪装成从节点，监听数据库的数据更新操作，从而将其转换为事件，
通过 Kafka 等消息组件通知到应用组件；

(Canal的流程图)

这种方式的好处在于：
通过监听数据变化的事件消息，我们便可以在应用层中删除对应的缓存，而且消息队列提供了重试的能力，
我们不需要担心删除缓存失败的场景，并且可以将缓存清理逻辑从数据库更新操作中剥离出来，提高代码简洁度和降低出错的概率。


这种方式的好处在于: 能保障系统最终一致 , 因为:
● 数据库只有事务成功后 (binlog写入成功), 才会发送更新操作, 触发缓存清理的逻辑; 也就意味着, 每个数据更新都有一个对应的缓存清理的操作, 所以能保证最后应用层还是要来查一遍最新数据的;
● MQ 一般是包含重试机制的, 理论上能够给保障最终旧的缓存一定会被清理掉;

{{< admonition type=warning title="低概率的数据不一致情况" open=open >}}
虽然该方案看起来十分完美了，但本质上它仍然是 **Cache Aside 模式**，只是将缓存清理的操作放在了另外一个地方罢了。
所以，它仍然无法摆脱可能存在的并发读写时的数据不一致问题，即某个线程读取到某个旧值，
此时假设另外一个线程完成了更新操作，并且应用程序马上接收到更新事件，删除了缓存，前面的线程才将读取到的旧值写入缓存的情况。

正如前面所说，这种情况发生的概率十分低，但我们仍然不能忽略，此处建议：
1. 所有读取底层存储的操作，当读取完毕之后，需要立马将值写入缓存。如果在此时进行一个耗时操作，再将值写入缓存，则加大了上述情况的发生概率；

2. 为所有的缓存设置过期时间，代表能容忍的、最长的数据不一致时间；
{{< /admonition >}}

### 一主多从的数据库架构
大多数生产环境中，关系型数据库我们会将其部署为 **一主多从架构，以此来实现读写分离**，降低主库的压力。

也就是说，应用层会有部分查询数据库的请求路由到从库中。此时如果我们只监听主库的更新就会产生问题，
因为收到主库更新事件时，即使我们将缓存删除了，但我们不能保证此时从库的数据已经跟主库保持一致了，
如果此时查询从库的请求获取到了旧的数据，又将这个旧的数据写入缓存，我们又会面临数据不一致的问题。

所以，这个问题的解法在于，我们不仅仅需要监听主库的更新，我们同样需要监听从库的更新事件。

{{< image src="https://i.bmp.ovh/imgs/2022/03/1447be7e176dc412.png" width="600" caption="数据库一主多从架构下的 Binlog 同步" >}}

在该场景中，因为我们无法精确地控制每个请求具体会调用到哪个从库，所以在所有的从库都同步到主库的进度之前，都会存在数据不一致的风险（即有线程读取了尚未同步的从库数据，将旧数据写入缓存）。
因此，我们需要监听每一个从库的 Binlog ，只要有一个从库更新了，我们就要对缓存进行清理。

假设我们是一主五从的架构，那么一个更新数据库的操作就将对应执行 **6 次**缓存清理操作，
虽然很不优雅，但为了保障一致性，似乎也没有更好的办法了。

### 集中式缓存和本地缓存
在实际项目中，除了 Redis 这一类的分布式缓存组件，有时我们也会将数据直接缓存在应用的本地内存中。
本地缓存具备更好的性能，并且可拓展性会比集中式缓存更好，常见的本地缓存如 Guava Cache 等。

本地缓存同样面临更新的问题，而且本地缓存的更新比集中式缓存稍微复杂一些，对于集中式缓存来说，只要在集群中的一个节点执行缓存清理操作即可。
但是对于本地缓存，每个节点都存在一份数据副本，为了保持一致，我们需要删除所有节点上的本地缓存数据。

综上所述，我们针对这两种缓存的处理采用以下策略：
- **集中式缓存** : 所有节点使用同一个 Kafka Consumer Group，只要其中一个节点收到数据更新事件，则清理集中式缓存的逻辑；

- **本地缓存** : 每个节点使用各自的 Kafka Consumer Group（比如使用 host 区分机器），当产生数据更新事件时，每个节点都会收到并执行清理本地缓存的逻辑；

### read-after-write场景
通过监听 Binlog 事件来删除缓存的方式比传统的手动删除方式更加通用，但是其仍然具备一些缺点，比如：

- **更新延迟** : 删除缓存的操作基于 Binlog 事件，事件要经过 MySQL -> Canal -> Kafka -> 应用程序 -> 缓存清理，整一条链路比手动删除缓存长许多，对于缓存何时会被删除，其实是没有保证的；

- **增加数据库压力** : 监听 Binlog 的组件是伪装成从节点进行工作的，所以主节点需要额外的资源来执行同步 Binlog 的任务，会对主库的性能造成一定的影响；（通常问题不大）

- **级联故障问题** : 相比于手动缓存清理操作，该方案关联的组件更多（Canal，Kafka等），任意一个节点出了问题都将导致缓存架构失效，可能会导致大规模的缓存不一致情况；

针对 **更新延迟** 的问题，如果我们系统中存在 **写后立即读** 的情况，比如下面的业务场景：

- 用户在个人页面编辑个人信息，发送请求更新页面；

- 更新数据成功之后，重新发起请求读取数据、加载页面；

这种问题就是典型的 **read-after-write** 情况，此处如果使用 Binlog 的方式去做，那么极有可能会读取到旧的数据（缓存未更新），用户会误以为更新没有成功。
在这种情况下，我们有以下几种手段解决：

1. **手动清理缓存** : 退回传统的手动缓存清理操作，更新操作完成后，使用代码直接清理缓存；

2. **避免使用缓存** : 考量应用场景，对于读取请求量不大、更新频繁的场景，尽量不实用缓存机制。缓存不是万能药，它还会给代码带来不必要的复杂性；

## Reference
- [缓存更新的套路](https://coolshell.cn/articles/17416.html)

- [并发环境下，先操作数据库还是先操作缓存？](https://juejin.cn/post/6844903907726983181)